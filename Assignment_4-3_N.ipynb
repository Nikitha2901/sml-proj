{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 4 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "---\n",
    "## Assignment 4, PROBLEM 1\n",
    "Maximum Points = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "\n",
    "This time the assignment only consists of one problem, but we will do a more comprehensive analysis instead.\n",
    "\n",
    "Consider the dataset `mammography.mat` that you can download from [http://odds.cs.stonybrook.edu/mammography-dataset/](http://odds.cs.stonybrook.edu/mammography-dataset/). Below you can find the code to load this file into `X` and `Y`, you just need to put the file in your `data` folder. During mammography the doctor would be looking for something called `calcification`, which is calcium deposits in the breast tissue and is used as an indicator of cancer. In this dataset the `X` corresponds to some measurements, there are 6 features. The `Y` is a 0-1 label where 1 represents calcification and 0 does not.\n",
    "\n",
    "1. [3p] Split the data into three parts, train/test/validation where train is 60% of the data, test is 15% and validation is 25% of the data. Do not do this randomly, I have prepared a shuffling with a fixed seed, this way I can make sure that we all did the same splits. That is [train,test,validation] is the splitting layout.\n",
    "2. [4p] Train a machine learning model on the training data (you are free to choose it yourself). Hint: you could always try `LogisticRegression`, but for it to work well you would need `StandardScaler` and put everything in a `Pipeline`.\n",
    "3. [3p] Use the classification report from `Utils` and compute the intervals for precision-recall etc on the test set with `union_bound correction` with 95% confidence.\n",
    "4. [3p] You are interested in minimizing the average cost of your classifier, but first we must define it:\n",
    "    * If someone is calcified but classified as not, we say it costs 30 **(this is the worst scenario)** \n",
    "    * If someone is not calcified but classified as calcified, we say it costs 5 **(this probably only costs extra investigation)**\n",
    "    * If someone is calcified but classified as calcified, costs 0 **(We did the right thing, no cost)**\n",
    "    * If someone is not calcified but classified as not, costs 0 **(We did the right thing, no cost)**.\n",
    "\n",
    "complete filling the function `cost` to compute the cost of a prediction model under a certain prediction threshold (recall our precision recall lecture and the `predict_proba` function from trained models). What would be the cost of having a model that always classifies someone as not calcified on the test set?\n",
    "\n",
    "5. [4p] Now, we wish to select the threshold of our classifier that minimizes the cost, we do that by checking say 100 evenly spaced proposal thresholds between 0 and 1, and use our testing data to compute the cost.\n",
    "6. [4p] With your newly computed threshold value, compute the cost of putting this model in production by computing the cost using the validation data. Also provide a confidence interval of the cost using Hoeffdings inequality with a 95% confidence.\n",
    "7. [3p] Let $t$ be the threshold you found and $f$ the model you fitted, if we define the random variable\n",
    "$$\n",
    "    C = 30(1-1_{f(X)\\geq t})Y+5(1-Y)1_{f(X) \\geq t}\n",
    "$$\n",
    "then $C$ denotes the cost of a randomly chosen patient. In the above we are estimating $\\mathbb{E}[C]$ using the empirical mean. However, since the number of calcifications in the population is fairly small and our classifier probably has a fairly high precision for the $0$ class, then $C$ should have fairly small variance. Compute the empirical variance of $C$ on the validation set. What would be the confidence interval if we used Bennett's inequality instead of Hoeffding in point 6 but with the computed empirical variance as our guess for the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [],
   "source": [
    "import scipy.io as so\n",
    "import numpy as np\n",
    "data = so.loadmat('data/mammography.mat')\n",
    "\n",
    "np.random.seed(0)\n",
    "shuffle_index = np.arange(0,len(data['X']))\n",
    "np.random.shuffle(shuffle_index)\n",
    "\n",
    "X = data['X'][shuffle_index,:]\n",
    "Y = data['y'][shuffle_index,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6709, 6) (1677, 6) (2797, 6) (6709,) (1677,) (2797,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=0.6)\n",
    "X_test,X_valid,Y_test,Y_valid = train_test_split(X_test,Y_test,test_size=0.625)\n",
    "\n",
    "\n",
    "# Split the X,Y into three parts, make sure that the sizes are\n",
    "# (6709, 6), (1677, 6), (2797, 6), (6709,), (1677,), (2797,)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_valid.shape, Y_train.shape, Y_test.shape, Y_valid.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844961240310077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 2\n",
    "# Use X_train,Y_train to train a model from sklearn. Make sure it has the predict_proba function\n",
    "# for instance LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline([('scaler', StandardScaler()), ('logistic regression', LogisticRegression())])\n",
    "model.fit(X_train,Y_train)\n",
    "#Y_pred = model.predict_proba(X_test)\n",
    "print(model.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            labels           precision             recall\n",
      "\n",
      "                 0  0.99 : [0.95,1.00] 1.00 : [0.96,1.00]\n",
      "                 1  0.88 : [0.54,1.00] 0.48 : [0.23,0.73]\n",
      "\n",
      "          accuracy                                        0.98 : [0.94,1.00]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 3\n",
    "\n",
    "# Compute precision and recall on the test set using \n",
    "from Utils import classification_report_interval\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report_interval(Y_test,y_pred,alpha=0.05))\n",
    "\n",
    "# Each precision and recall should be a tuple, for instance you can write\n",
    "# precision0 = (0.9,0.95)\n",
    "\n",
    "precision0 = (0.94,1.00)\n",
    "recall0 = (0.95,1.00)\n",
    "precision1 = (0.22,1.00)\n",
    "recall1 = (0.03,0.59)\n",
    "\n",
    "# The code below will check that you supply the proper type\n",
    "assert(type(precision0) == tuple)\n",
    "assert(len(precision0) == 2)\n",
    "assert(type(recall0) == tuple)\n",
    "assert(len(recall0) == 2)\n",
    "assert(type(precision1) == tuple)\n",
    "assert(len(precision1) == 2)\n",
    "assert(type(recall1) == tuple)\n",
    "assert(len(recall1) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 4\n",
    "\n",
    "def cost(model,threshold,X,Y):\n",
    "    pred_proba = model.predict_proba(X)[:,1]\n",
    "    predictions = (pred_proba >= threshold)*1\n",
    "    \n",
    "    \n",
    "    # Fill in what is missing to compute the cost and return it\n",
    "    # Note that we are interested in average cost (cost per person)\n",
    "    \n",
    "    cost = 0;\n",
    "    \n",
    "    for m,n in enumerate(predictions):\n",
    "        if n!= Y[m]:\n",
    "            if n==1 : \n",
    "                cost += 5\n",
    "            else:\n",
    "                cost += 30\n",
    "    \n",
    "    return cost/len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5575432319618366"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 4\n",
    "\n",
    "# Fill in the naive cost of the model that would classify all as non-calcified on the test set\n",
    "naive_cost = cost(model,0.8,X_test,Y_test)\n",
    "naive_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11111111111111112 0.30709600477042337\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Part 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in np.linspace(0,1,num=100):\n",
    "    c=cost(model,i,X_test,Y_test)\n",
    "    x.append(i)\n",
    "    y.append(c)\n",
    "\n",
    "plt.plot(x,y)\n",
    "    \n",
    "optimal_threshold = x[y.index(min(y))]\n",
    "cost_at_optimal_threshold = min(y)\n",
    "print(optimal_threshold,cost_at_optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.4432477844798585, 1.097520219231378) 0.32713621737575976\n"
     ]
    }
   ],
   "source": [
    "# Part 6\n",
    "from Utils import epsilon_bounded\n",
    "\n",
    "cost_at_optimal_threshold_validation = cost(model,0.11111111111111112,X_valid, Y_valid)\n",
    "# Report the cost interval as a tuple cost_interval = (a,b)\n",
    "eps_val=epsilon_bounded(len(X_valid),30, 0.05)\n",
    "cost_interval = (cost_at_optimal_threshold_validation-eps_val, cost_at_optimal_threshold_validation+eps_val)\n",
    "print(cost_interval,cost_at_optimal_threshold_validation)\n",
    "\n",
    "# The code below will tell you if you filled in the intervals correctly\n",
    "assert(type(cost_interval) == tuple)\n",
    "assert(len(cost_interval) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11616499060679385"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 7\n",
    "\n",
    "variance_of_C = sum((x-cost_at_optimal_threshold_validation)**2 for x in Y_valid)/(len(Y_valid))\n",
    "variance_of_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical error 9.08995101411847e-16\n",
      "(0.29895516517182014, 0.3553172695796994)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 7\n",
    "from Utils import bennett_epsilon\n",
    "\n",
    "# A 95% confidence interval of the random variable C using Bennett's inequality\n",
    "sigma_val=np.sqrt(variance_of_C)\n",
    "eps_val=bennett_epsilon(len(X_valid), 30,sigma_val, 0.05 )\n",
    "interval_of_C = (cost_at_optimal_threshold_validation-eps_val,cost_at_optimal_threshold_validation+eps_val)\n",
    "print(interval_of_C)\n",
    "\n",
    "assert(type(interval_of_C) == tuple)\n",
    "assert(len(interval_of_C) == 2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lx_assignment_number": 4,
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
